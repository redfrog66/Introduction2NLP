{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd071f835d09f2dc7658b8bfea70337fd38a098aa1e53e53fe645aaa17deb87e84b",
   "display_name": "Python 3.7.9 64-bit ('E01': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "600901\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/nietzsche.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "maxlen = 60\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'preface\\n\\n\\nsupposing that truth is a woman--what then? is the'  :  r\n'face\\n\\n\\nsupposing that truth is a woman--what then? is there '  :  n\n'e\\n\\n\\nsupposing that truth is a woman--what then? is there not'  :   \n'\\nsupposing that truth is a woman--what then? is there not gr'  :  o\n'pposing that truth is a woman--what then? is there not groun'  :  d\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): print(repr(sentences[i]),\" : \", next_chars[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¤', '¦', '©', '«', 'ã', '†']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '=': 22, '?': 23, '[': 24, ']': 25, '_': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52, '¤': 53, '¦': 54, '©': 55, '«': 56, 'ã': 57, '†': 58}\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru (GRU)                    (None, 16)                3696      \n_________________________________________________________________\ndense (Dense)                (None, 59)                1003      \n=================================================================\nTotal params: 4,699\nTrainable params: 4,699\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(16, input_shape=(maxlen, len(chars))),\n",
    "    tf.keras.layers.Dense(units=len(chars), activation='softmax')\n",
    "]) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "1565/1565 [==============================] - 71s 46ms/step - loss: 2.2914\n",
      "Epoch 2/2\n",
      "1565/1565 [==============================] - 82s 52ms/step - loss: 2.0561\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be7dd30308>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.fit(x, \n",
    "          y,\n",
    "          batch_size=128,\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'-he forces it to say nay, where he would like\\nto affirm, lov'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "base_text = text[start_index: start_index + maxlen]\n",
    "base_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Temp:  0.2\n",
      "-he forces it to say nay, where he would like\n",
      "to affirm, lov\n",
      "e and the and as and the preastion of the and the such and the of the and and the greation and and and and and the might of the and and of of the and the the the more the the for of one and of the of \n",
      "Temp:  0.5\n",
      "f the and the the the more the the for of one and of the of \n",
      "want and the of the in the suth and of in has of preation the preast suth is of the of\n",
      "beself and ploust of the man of as and indersenster as a the conthing are have and the mand of the the and attos \n",
      "Temp:  1.0\n",
      "s a the conthing are have and the mand of the the and attos \n",
      "ean abtionsly aldion axes. of has of whis, our of of\n",
      "mar,\n",
      "(wabition--a for ar\n",
      "and of hanaltion the maistorenes and thoubshe winell\n",
      "is to depion of fee romophioug\n",
      "resannsise his to the co\n",
      "casinwenw he \n",
      "Temp:  1.2\n",
      "ion of fee romophioug\n",
      "resannsise his to the co\n",
      "casinwenw he \n",
      "elcentisonttanity extedloctpod imtimur; veudiceniture,\n",
      "whail, stpith to, indnom feless\n",
      "groy relil buply of simips pleing, bostue! inday as; remabsed\n",
      "intzet\n",
      "sauld\n",
      "tprich\n",
      "morg, deaes and\n",
      "law con:\n",
      "rote n\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "temperatures = [0.2, 0.5, 1.0, 1.2]\n",
    "gen_characters = 200\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(\"Temp: \", temp)\n",
    "    generated_text = base_text\n",
    "    print(generated_text)\n",
    "    for i in range(gen_characters):\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(sampled, verbose=0)[0]        \n",
    "        next_index = sample(preds, temp)\n",
    "        next_char = chars[next_index]\n",
    "\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  }
 ]
}