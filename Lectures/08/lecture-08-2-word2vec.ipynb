{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/simpsons_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 158314 entries, 0 to 158313\nData columns (total 2 columns):\n #   Column              Non-Null Count   Dtype \n---  ------              --------------   ----- \n 0   raw_character_text  140500 non-null  object\n 1   spoken_words        131855 non-null  object\ndtypes: object(2)\nmemory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Miss Hoover</td>\n      <td>No, actually, it was a little of both. Sometim...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lisa Simpson</td>\n      <td>Where's Mr. Bergstrom?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miss Hoover</td>\n      <td>I don't know. Although I'd sure like to talk t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lisa Simpson</td>\n      <td>That life is worth living.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Edna Krabappel-Flanders</td>\n      <td>The polls will be open from now until the end ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "raw_character_text    17814\n",
       "spoken_words          26459\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "raw_character_text    0\n",
       "spoken_words          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 131853 entries, 0 to 131852\nData columns (total 2 columns):\n #   Column              Non-Null Count   Dtype \n---  ------              --------------   ----- \n 0   raw_character_text  131853 non-null  object\n 1   spoken_words        131853 non-null  object\ndtypes: object(2)\nmemory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df[\"spoken_words\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'little',\n",
       " 'sometimes',\n",
       " 'disease',\n",
       " 'magazine',\n",
       " 'news',\n",
       " 'show',\n",
       " 'natural',\n",
       " 'think']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "w_n_lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "corpus = [[w_n_lemmatizer.lemmatize(word) for word in word_tokenize(document.lower()) \n",
    "            if not word in stop_words and word.isalnum()] \n",
    "          for document in corpus]\n",
    "\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\opell.desktop-ueq8dpv\\anaconda3\\envs\\e01\\lib\\site-packages (3.8.3)\nRequirement already satisfied: smart-open>=1.8.1 in c:\\users\\opell.desktop-ueq8dpv\\anaconda3\\envs\\e01\\lib\\site-packages (from gensim) (4.2.0)\nRequirement already satisfied: scipy>=0.18.1 in c:\\users\\opell.desktop-ueq8dpv\\anaconda3\\envs\\e01\\lib\\site-packages (from gensim) (1.5.2)\nRequirement already satisfied: six>=1.5.0 in c:\\users\\opell.desktop-ueq8dpv\\anaconda3\\envs\\e01\\lib\\site-packages (from gensim) (1.15.0)\nRequirement already satisfied: numpy>=1.11.3 in c:\\users\\opell.desktop-ueq8dpv\\anaconda3\\envs\\e01\\lib\\site-packages (from gensim) (1.18.5)\nRequirement already satisfied: numpy>=1.11.3 in c:\\users\\opell.desktop-ueq8dpv\\anaconda3\\envs\\e01\\lib\\site-packages (from gensim) (1.18.5)\nNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Phrases<376859 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "phrases = Phrases(corpus, min_count=30, progress_per=10000)\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "131853"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "w2v_model.build_vocab(corpus, progress_per=10000)\n",
    "w2v_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7634342, 19971480)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "w2v_model.train(corpus, \n",
    "                total_examples=w2v_model.corpus_count, \n",
    "                epochs=30, \n",
    "                report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which will make the model much more memory-efficient:\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('marge', 0.7151126861572266),\n",
       " ('settled', 0.6487970948219299),\n",
       " ('eliza', 0.6143308877944946),\n",
       " ('simpson', 0.6072618365287781),\n",
       " ('abe', 0.6037951111793518),\n",
       " ('sorry', 0.5871919393539429),\n",
       " ('supervisor', 0.5862137079238892),\n",
       " ('yoink', 0.5815441012382507),\n",
       " ('pfft', 0.577323317527771),\n",
       " ('asking', 0.5765624046325684)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('homer', 0.7151126861572266),\n",
       " ('husband', 0.6739974617958069),\n",
       " ('nooooo', 0.6439752578735352),\n",
       " ('becky', 0.6334644556045532),\n",
       " ('fishing', 0.6333003640174866),\n",
       " ('badly', 0.6299690008163452),\n",
       " ('sharing', 0.629048228263855),\n",
       " ('homie', 0.6263099312782288),\n",
       " ('noooo', 0.6262434124946594),\n",
       " ('arranged', 0.6240975856781006)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"marge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('lisa', 0.7769181728363037),\n",
       " ('mom', 0.7092975974082947),\n",
       " ('eliza', 0.6429473161697388),\n",
       " ('jessica', 0.6156376004219055),\n",
       " ('maggie', 0.6118208169937134),\n",
       " ('shh', 0.6051841974258423),\n",
       " ('creepy', 0.6046707034111023),\n",
       " ('assignment', 0.6038774847984314),\n",
       " ('substitute', 0.5964770317077637),\n",
       " ('concerned', 0.5958867073059082)]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"bart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.64294726"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"eliza\", 'bart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\opell.DESKTOP-UEQ8DPV\\anaconda3\\envs\\E01\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'milhouse'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('man', 0.5287352800369263),\n",
       " ('younger', 0.5231418609619141),\n",
       " ('impressive', 0.5067380666732788)]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Which word is to woman as homer is to marge?\n",
    "w2v_model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"marge\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('lisa', 0.5924097299575806),\n",
       " ('pregnant', 0.5832182168960571),\n",
       " ('mom', 0.5476857423782349)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.save_word2vec_format(\"../data/word2vec.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/word2vec.vec\", \"r\") as f:\n",
    "    tmp = f.read().split(\"\\n\")\n",
    "\n",
    "with open(\"../data/word2vec.tsv\", \"w\") as t:\n",
    "    for i in range(1,len(tmp)):\n",
    "        splited = tmp[i].split(\" \")\n",
    "        t.write(\"\\t\".join(splited[1:]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}