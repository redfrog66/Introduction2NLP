{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "py37_tensorflow",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 568454 entries, 0 to 568453\nData columns (total 10 columns):\n #   Column                  Non-Null Count   Dtype \n---  ------                  --------------   ----- \n 0   Id                      568454 non-null  int64 \n 1   ProductId               568454 non-null  object\n 2   UserId                  568454 non-null  object\n 3   ProfileName             568438 non-null  object\n 4   HelpfulnessNumerator    568454 non-null  int64 \n 5   HelpfulnessDenominator  568454 non-null  int64 \n 6   Score                   568454 non-null  int64 \n 7   Time                    568454 non-null  int64 \n 8   Summary                 568427 non-null  object\n 9   Text                    568454 non-null  object\ndtypes: int64(5), object(5)\nmemory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "df = pd.read_csv(\"./Reviews.csv\")\n",
    "df.info()\n",
    "\n",
    "#df[\"Score\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 568454 entries, 0 to 568453\nData columns (total 2 columns):\n #   Column  Non-Null Count   Dtype \n---  ------  --------------   ----- \n 0   Score   568454 non-null  int64 \n 1   Text    568454 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "del df[\"Id\"], df[\"ProductId\"], df[\"UserId\"], df[\"ProfileName\"], df[\"HelpfulnessNumerator\"], df[\"HelpfulnessDenominator\"], df[\"Time\"], df[\"Summary\"]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({5: 363122, 4: 80655, 1: 52268, 3: 42640, 2: 29769})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = list(df[\"Score\"])\n",
    "cu = Counter(c)\n",
    "print(cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29769\n14884\n9922\n4961\n"
     ]
    }
   ],
   "source": [
    "len_reviews = 29769\n",
    "print(len_reviews)\n",
    "\n",
    "len_train = int(round(len_reviews * 0.5))\n",
    "len_val = (len_reviews - len_train) // 3 * 2\n",
    "len_test = (len_reviews - len_train) // 3\n",
    "\n",
    "print(len_train)\n",
    "print(len_val)\n",
    "print(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.loc[df['Score'] == 1].copy()\n",
    "df_2 = df.loc[df['Score'] == 2].copy()\n",
    "df_3 = df.loc[df['Score'] == 3].copy()\n",
    "df_4 = df.loc[df['Score'] == 4].copy()\n",
    "df_5 = df.loc[df['Score'] == 5].copy()\n",
    "\n",
    "df_1_train = df_1[:len_train].copy()\n",
    "df_2_train = df_2[:len_train].copy()\n",
    "df_3_train = df_3[:len_train].copy()\n",
    "df_4_train = df_4[:len_train].copy()\n",
    "df_5_train = df_5[:len_train].copy()\n",
    "\n",
    "df_1_val = df_1[len_train:len_train+len_val].copy()\n",
    "df_2_val = df_2[len_train:len_train+len_val].copy()\n",
    "df_3_val = df_3[len_train:len_train+len_val].copy()\n",
    "df_4_val = df_4[len_train:len_train+len_val].copy()\n",
    "df_5_val = df_5[len_train:len_train+len_val].copy()\n",
    "\n",
    "df_1_test = df_1[len_train+len_val:len_train+len_test+len_val].copy()\n",
    "df_2_test = df_2[len_train+len_val:len_train+len_test+len_val].copy()\n",
    "df_3_test = df_3[len_train+len_val:len_train+len_test+len_val].copy()\n",
    "df_4_test = df_4[len_train+len_val:len_train+len_test+len_val].copy()\n",
    "df_5_test = df_5[len_train+len_val:len_train+len_test+len_val].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_1_train, df_2_train, df_3_train, df_4_train, df_5_train])\n",
    "df_train = df_train.sample(frac=1)\n",
    "#df_train[\"Score\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.concat([df_1_val, df_2_val, df_3_val, df_4_val, df_5_val])\n",
    "df_val = df_val.sample(frac=1)\n",
    "#df_val[\"Score\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_1_test, df_2_test, df_3_test, df_4_test, df_5_test])\n",
    "df_test = df_test.sample(frac=1)\n",
    "#df_test[\"Score\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer  \n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#pip install spacy\n",
    "#python -m spacy download en\n",
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before removing stopwords:\n        Score                                               Text\n185797      3  Product is very grainy........not what I expec...\n77873       3  The Switch Black Cherry soda is a fine drink i...\n70612       4  I really like Nana's cookies and have placed s...\n3830        5  I first saw this product, Panda Licorice, at t...\n19710       5  This baby food is both convenient and healthy....\n20812       4  I usually buy loose leaf Taylors Darjeeling te...\n119238      2  I was really excited when I found these and wa...\n20975       5  My wife's favorite tea ever. She was very diss...\n185910      3  I am a firm believer that cats should eat good...\n3182        5  I am so happy that Amazon got these back in so...\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing stopwords:\")\n",
    "print(df_train.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "df_train[\"Text\"] = df_train[\"Text\"].apply(lambda row: \" \".join([word.lower() for word in word_tokenize(row) if not word.lower() in stop_words and word.lower().isalpha()]))\n",
    "\n",
    "df_train[\"Text\"] = df_train[\"Text\"].apply(stemmer.stem)\n",
    "\n",
    "df_train[\"Text\"] = df_train[\"Text\"].apply(lambda row: \" \".join([word.lemma_ for word in nlp(row)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "After removing stopwords:\n        Score                                               Text\n185797      3  product grainy expect shipping cost line send ...\n77873       3  switch black cherry soda fine drink enjoy carb...\n70612       4  really like nana cookie place several order pe...\n3830        5  first see product panda licorice memphis tn zo...\n19710       5  baby food convenient healthy great worry son e...\n20812       4  usually buy loose leaf taylor darjeeling tea h...\n119238      2  really excite find want try right away receive...\n20975       5  wife favorite tea ever dissapointe local store...\n185910      3  firm believer cat eat good meat lot protein av...\n3182        5  happy amazon get back could order second case ...\n"
     ]
    }
   ],
   "source": [
    "print(\"After removing stopwords:\")\n",
    "print(df_train.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"Text\"] = df_val[\"Text\"].apply(lambda row: \" \".join([word.lower() for word in word_tokenize(row) if not word.lower() in stop_words and word.lower().isalpha()]))\n",
    "\n",
    "df_val[\"Text\"] = df_val[\"Text\"].apply(stemmer.stem)\n",
    "\n",
    "df_val[\"Text\"] = df_val[\"Text\"].apply(lambda row: \" \".join([word.lemma_ for word in nlp(row)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"Text\"] = df_val[\"Text\"].apply(lambda row: \" \".join([word.lower() for word in word_tokenize(row) if not word.lower() in stop_words and word.lower().isalpha()]))\n",
    "\n",
    "df_train[\"Text\"] = df_train[\"Text\"].apply(lambda row: \" \".join([word.lower() for word in word_tokenize(row) if not word.lower() in stop_words and word.lower().isalpha()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./Review_train.csv\")\n",
    "df_val.to_csv(\"./Review_val.csv\")\n",
    "df_test.to_csv(\"./Review_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}